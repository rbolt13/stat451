---
title: "Chapter 3 : Discrete Random Variables and Probability Distribution"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'chapter3.html'))})
output: 
  html_document: rmdformats::readthedown
---
```{r, echo=F, message=F}
library(dplyr)
library(kableExtra) # highlights table when hover over a line
```

## Definitions

> For a given sample space $\mathscr{S}$ of some experiment, a **random variable (rv)** is any rule that associates a number with each outcome in $\mathscr{S}$. In mathematical language, a random variable is a funciton whose domain is the sample space and whose range is the set of real numbers. 

* Random variables are denoted by uppercase letters such as $X$ and $Y$. 

> Any random variable whose only possible values are 0 and 1 is called a **Bernoulli random variable** . 

> A **discrete** random variable is an rv whose possible values either consitiute a finite set or else can be listed in an infinite sequence in which there is a first element, a second element, and so on ("countable" infinite).

> A random variable is **continuous** if *both* of the following apply:
1. Its set of possible values consists either of all numbers in a single interval on the number line ($-\infty$ to $\infty$) or all number in a disjoint union of such intervals ($[0,10] \cap [20, 30]$). 

> The **Probability distribution** or **probability mass function** (pmf) of a discrete rv is defined for every number $x$ by $p(x)=P(X=x)=P($all $\omega \in \mathscr{S}:X(\omega)=x)$.

> Suppose $p(x)$ depends on a quantity that can be assigned any one of a number of possible values, with each different value determining a different probability distribution. Such a quantity is called a **parameter** of the distribution. The collection of all probability distributions for different value of the parameter is called a **family** of probability distributions. 

* Sometimes expressed $p(x;\alpha)$, where $\alpha$ is the parameter

* The Bernoulli family of distributions is between 0 and 1. 

> The **cumulative distribution** (cdf) $F(x)$ of a discrete random variable $X$ with pmf p(x) is defined for every number x by $$F(x)=P(X \leq x)=\sum_{y:y \leq x}^{} p(y)$$ For any number $x$, $F(x)$ is the probability that the observed value of $X$ will be at most x. 

> Let $X$ be a discrete random variable of possible values D and pmf $p(x)$. The **expected value** or **mean value** of $X$ denoted by $E(X)$ of $\mu x$ or just $\mu$, is $$E(X)=\mu x = \sum_{x \in D}^{} x\cdot p(x)$$

> Let $X$ have pmf p(x) and expected value $\mu$. Then the **variance** of $X$, denoted by $V(X)$ or $\sigma_{X}^2$ or just $\sigma ^2$, is $$V(X)=\sum_{D}^{} (x-\mu)^2 \cdot p(x)=E(X-\mu)^2]$$ The **standard deviation** (SD) of X is $$\sigma x \sqrt{ \sigma_{X}^2}$$ 

> An experiment for which **Condition 1**, **Condition 2**, **Condition 3**, **Condition 4** (a fixed number of dichotomous, independent, homogenous trials) are satisfied is called a **binomial experiment**.  

> The **binomial random variable X** associated with a binomial experiment consisting of $n$ trials is defined as $X =$ the number of S's among the n trials.

* because the pmf of a binomial random variable X depends on the two parameters $n$ and $p$, we denote the pmf by $b(x;n,p)$

> The random variable of interest is X = the number of failures that preced the rth success; X is called a **negative binomial random variable** because, in contrast to the binomial rv, the number of successes is fixed and the number of trials is random. 

> Both X = number of F's and Y = number of tirals $(=1+X)$ are referred to in the literature as **geometric random variables**, with its corresponding pmf called the **geometric distributions**

* $Y = X - Y

> A discrete random variable X is said to have a **Poisson distribution** with parameter $\mu (\mu >0)$ if the pmf of X is $$P(x;\mu )=\frac{e^{-\mu}\cdot \mu ^{x}}{x!}$$ $x=0,1,2,3,....$

## Theorems

> **Proposition - Computing Probabilities :** For any two numbers $a$ and $b$ with $a \leq b$, $$ P(a \leq X \leq b)=F(b)-F(a-)$$ where "$a-$" represents the largest possible X value that is strickly less than $a$. In particular, if the only possible values are integers and $a$ and $b$ are integers, then $$P(a \leq X \leq b)=P(X=a or a+1 or ..... or b) = F(b)-F(a-1)$$ Taking $a=b$ yields $P(X=a)=F(a)-F(a-1)$ in this case. 

* mainly used for binomial and Poisson probabilities

> **Proposition - Expected Value of a Function : **If the random variable $X$ has a set of possible values D and pmf $p(x)$, then the expected value of any function $h(X)$, denothed by $E[h(X)]$ or $\mu_{h(x)}$ is computed by $$E[h(X)]=\sum_{D}^{} h(x) \cdot p(x)$$


> **Proposition - Expected Value of a Linear Function : **$$E(aX+b)=a\cdot E(X)+b$$ (Or, using alternative notation, $\mu_aX+b = a\cdot \mu x +b$). To paraphrase, the expected value of a linear function equals the linear function evaluated at the expected value $E(X)$. 

Two important rules of expected values :

1. For any constant $a,E(aX)=a\cdot E(x)$ (take $b=0$).

2. For any constant $b,E(bx)=E(X)+b$ (take $a = 1$).

> **Proposition - Shortcut for $\sigma^2$ : ** $$V(X)=\sigma^2=[\sum_{D} x^2\cdot p(x)]-\mu^2=E(X^2)-[E(X)]^2$$

> **Proposition - Variance of a Linear Function : **$$V(aX)+b=\sigma_{aX+b}^2 = a^2 \cdot \sigma_{X}^{2}$$ and $$\sigma_{aX+b} = |a| \cdot \sigma_X$$ In particular, $$\sigma_{aX} = |a| \cdot \sigma X, \sigma_{X+b}=\sigma X$$

> **Rule - binomial "without-replacement" : **Consider sampling without replacement from a dichotomous population of size N. if the sample size (number of trials) $n$ is at most 5% of the population size, the experiment can be analyzed as though it were a binomial experiment. 

* dichotomous : divided into two branches 

> **Theorem - Binomial Probability :**\usepackage{amsmath}
\[ 
b(x;n,p) = \begin{cases}
      (\frac{n}{p})p^x(1-p)^{n-x} & x =0,1,2,...n \\
      0 &\text{otherwise}\
   \end{cases}
\]
In otherwords: 
\[ 
b(x;n,p) = \begin{cases}
      \text{number of sequences of} \\
      \text{length n consisting of x S's}\
   \end{cases} \cdot \begin{cases}
      \text{probability of any} \\
      \text{particular such sequence}\
   \end{cases}
\]

> **Proposition - The Mean and Variance of X :**If $X$~Bin$(n,p)$, then $E(X)=np$, $V(X)=np(1-p)=npq$, and $\sigma x=\sqrt{npq}$ (where $q=1-p$)

> **Proposition - Hypergeometric distribution : **If $X$ is the number of S's (successes) in a completely random sample of size $n$ drawn from a population consisting of M S's and $(N-M)$F's (failures), then the probability distribution of $X$, called the **hypergeometric distribution**, is given: $$P(X=x)=h(x;n,M,N)=\frac{{M\choose x}{N-M\choose n-x}}{{N\choose n}}$$ for x an integer satisfying max$(o,n-N+M)\leq x\leq min(n,M)$.

> **Proposition - Mean and Variance of Hypergeometric Distribution : **The mean and variance of the hypergeometric rv $X$ having pmf $h(x;n,M,N)$ are $$E(x)=n\cdot\frac{M}{N}$$  $$V(X)=(\frac{N-n}{N-1})\cdot n\cdot \frac{M}{N}\cdot (1-\frac{M}{N})$$

> **Proposition - pmf of the negatiative binomial: **The pmf of the negative binomial rv X with parameters r = number of S's and $p=P(S)$ is $$nb(x;r,p)={x+r-1\choose r-1}p^{r}(1-p)^{x}$$ x = 1,2, ...

> **Proposition - Expected Value and Variance of a Negative Binomial :** If X is a negative binomial rv with pmf $nb(x;r,p)$, then $$E(X)=\frac{r(1-p)}{p}$$ $$ V(X)=\frac{r(1-P)}{p^{2}}$$

> **Proposition - The Poisson Disribution as a Limit :** Suppose that in  the binomial pmf $b(x;n,p)$, we let $n\rightarrow \infty$ and $p\rightarrow 0$ in such a way that $np$ approaches a value $\mu > 0$ . Then $b(x;n,p)\rightarrow p(x;\mu)$

> **Proposition - The Mean and Variance of X for Poisson Distribution :** If X has a poisson distribution with parameter $\mu$ , then $E(X)=V(X)=\mu$ .

> **Assumptions - The Poisson Process :** 
> ![](img/3.6pp.png)

> **Proposition - Poisson Process Expected Number :** $P_{k}(t)=e^{-\alpha t}\cdot \frac{(\alpha t)^{k}}{k!}$ , so that the number of events during a time interval of length t is a Poisson rv with parameter $\mu = \alpha t$ . The expected number of events during any such time interval is then $\alpha t$ , so the expected number during a unit interval of time is $\alpha$ .

# Examples

### In Class Example 1 : (7-8-2021)
\[ 
p(x) = \begin{cases}
      {4\choose 4}p^x (1-p)^{4-x} & x =0,1,2,3, 4 \\
      0 &\text{otherwise}\
   \end{cases}
\]
```{r, echo=F}
x <- c(0:4)
p.x <- c("1/16", "4/16", "6/16", "4/16", "1/16")
df <- data.frame("x" = x, "p.x" = p.x)
df_new <- as.data.frame(t(df))
options(scipen = 50) # get rid of e's
rownames(df_new) <- c("x", "p(x)")
kable(df_new, col.names = NULL, align = "cccccc") %>%
  kable_paper()%>%
  kable_material(c( "hover")) %>%
  column_spec(1, bold = T, border_right = T) 
```

Suppose $p=\frac{1}{4} = 0.25$

$p(0)={4\choose 0}(0.25)^{0}(0.75)^{4}=0.316$

$p(0)={4\choose 1}(0.25)^{1}(0.75)^{3}=0.420$

$p(0)={4\choose 2}(0.25)^{2}(0.75)^{2}=0.211$

$p(0)={4\choose 3}(0.25)^{3}(0.75)^{1}=0.047$

$p(0)={4\choose 4}(0.25)^{4}=0.004$

### In Class Example 2 : (7-8-2021)
***A shipment of 7 TV sets contains 2 defective TV's. A random sample of 3 TV's is tested. Let X = the number of defective TV's in the sample. x is a discrete r.v.** 
```{r, echo=F}
x <- c(0:2)
p.x <- c("2/7", "4/7", "1/7")
df <- data.frame("x" = x, "p.x" = p.x)
df_new <- as.data.frame(t(df))
options(scipen = 50) # get rid of e's
rownames(df_new) <- c("x", "p(x)")
kable(df_new, col.names = NULL, align = "cccccc") %>%
  kable_paper()%>%
  kable_material(c( "hover")) %>%
  column_spec(1, bold = T, border_right = T) 
```

$p(0)=P[X=0]=\frac{{5\choose 3}}{{7\choose 3}}=\frac{2}{7}$

$p(0)=P[X=1]=\frac{{2\choose 1}{5\choose 3}}{{7\choose 3}}=\frac{4}{7}$

$p(0)=P[X=2]=\frac{{2\choose 2}{5\choose 2}}{{7\choose 3}}=\frac{1}{7}$

$p(0)=P[X=x]=\frac{{2\choose x}{5\choose 3-x}}{{7\choose 3}}, x = 0 , 1, 2$

### Exercise 24 (page 108)
![](img/3.24.png)

```{r, echo=F}
x <- c("1", "3", "4", "6", "12")
p.x <- c("0.30", "0.10", "0.05", "0.15", "0.40")
df <- data.frame("x" = x, "p.x" = p.x)
df_new <- as.data.frame(t(df))
options(scipen = 50) # get rid of e's
rownames(df_new) <- c("x", "p(x)")
kable(df_new, col.names = NULL, align = "cccccc") %>%
  kable_paper()%>%
  kable_material(c( "hover")) %>%
  column_spec(1, bold = T, border_right = T) 
```

b. $P[x\leq x\leq 6]=P[x\leq 6]-P[x<3]$=F(6)-F(3-)=0.60 - 0.30 = 0.30

### Exercise 13 (page 108)
Two fair six-sided dice are tossed independetly. Let M = the maximum of the two tosses (so M(1,5) = 5, M(3,3) = 3, ect.)

a. **What is the pmf of M? [Hint: First determine $p(1)$, then $p(2)$, and so on.]**

p(1)=p[M=1]=p(1,1)=p[1 with the frist die] x p[1 with the second die] = $\frac{1}{6} \cdot \frac{1}{6}=\frac{1}{36}$

p(2)=p[M=2]=p((1,2), (2,1), (2,2))=$\frac{1}{36}+ \frac{1}{36}+ \frac{1}{36} =\frac{3}{36}$

p(3)=p[M=3]=p((1,3), (2,3), (3,3), (3,1), (3,2))= $\frac{5}{36}

p(3)=p[M=3]=p((1,4), (2,4), (3,4), (4,4), (4,1), (4,2), (4,3))= $\frac{7}{36}

p(5)= $\frac{9}{36}$

p(6)= $\frac{11}{36}$

```{r, echo=F}
x <- c(1:6)
p.x <- c("1/36", "3/36", "5/36", "7/36", "9/36", "11/36")
df <- data.frame("x" = x, "p.x" = p.x)
df_new <- as.data.frame(t(df))
options(scipen = 50) # get rid of e's
rownames(df_new) <- c("M", "p(m)")
kable(df_new, col.names = NULL, align = "cccccc") %>%
  kable_paper()%>%
  kable_material(c( "hover")) %>%
  column_spec(1, bold = T, border_right = T) 
```

b. **Determine the cdf of M and graph it. ** 

### Exercise 13 (page 108)
A mail-order computer buisness has six telephone lines. Let X denote the numebrof lines in use at a specified time. Suppose the pmf of X is given in the accompanying table. 
```{r, echo=F}
x <- c(0:6)
p.x <- c("0.10", "0.15", "0.20", "0.25", "0.20", "0.06", "0.04")
df <- data.frame("x" = x, "p.x" = p.x)
df_new <- as.data.frame(t(df))
options(scipen = 50) # get rid of e's
rownames(df_new) <- c("x", "p(x)")
kable(df_new, col.names = NULL, align = "cccccc") %>%
  kable_paper()%>%
  kable_material(c( "hover")) %>%
  column_spec(1, bold = T, border_right = T) 
```
a. **at most three lines are in use**

P[$3\leq 3$]=p(0)+p(1)+p(2)+p(3)=0.1+0.15+0.2+0.25=0.7

b. **fewer than three lines are in use**

P[$x<3$]=0.45

c. **at least three lines are in use**

P[$x\geq 3$]=1-P[$x<3$]=0.55

d. **between two and five lines, inclusive, are in use**

P[$2<x\leq 5$]=p(2)+p(3)+p(4)+p(5)=0.71

e. **between two and four lines, inclusive, are not in use**

= 0.65

f. **at least four lines are not in use** 

0.45

### Exercise 14 (page 108)
![](img/3.14.png)

$\sum{}^{5} k(y)$=1=k(1+2+3+4+5)=15k

$k=\frac{1}{15}$

### Exercise 36 (page 116)
Let $X$ be the damage incurred (in dollars) in a certain type of accident during a given year. Possible $X$ values are 0, 1000, 5000, 10000, with probabilities of 0.8, 0.1, 0.08, 0.02, respectively. A particular company offers a 500 dollars deductible policy. If the company wishes its expected profit to be 100 dollars, what premium amount should it charge?  

X = Damage incurred 

Y = h(x) = Amount the company pays = x - 500

```{r, echo = F}
x <- c(0, 1000, 5000, 10000)
p.x <- c(0.8, 0.1, 0.08, 0.02)
p.y <- c(0, 500, 4500, 9500)
damage.payout <- data.frame("x" = x, "p.x" = p.x, "p.y" = p.y)
damage.payout_new <- as.data.frame(t(damage.payout))
options(scipen = 50) # get rid of e's
kable(damage.payout_new, col.names = NULL) %>%
  kable_paper()
```

E[Y]=0(0.8) + 500(0.1) + 4500(0.08) + 9500(0.02) = 600 dollars

### Exercise 32 (page 16)
A certain brand of upright freezer is available in three different rated capacities: $16ft^3$, $18ft^3$, and $20ft^3$. Let $X=$ the rated capacity of a freezer of this brand sold at a certain store. Suppose that $X$ has pmf: 
```{r, echo=F}
x <- c(16,18,20)
p.x <- c(0.2,0.5,0.3)
df <- data.frame("x" = x, "p.x" = p.x)
df.new <- as.data.frame(t(df))
options(scipen = 50)
kable(df.new, col.names = NULL) %>%
  kable_paper()
```
a. **Compute $E(X)$, $E(X^2)$, and $V(X)$.**

E[x] = 16(0.2) + 18(0.5) + 20(0.3) = 3.2 + 9 + 6 = 18.2

E[$x^2$] = $16^2$(0.2) + $18^2$(0.5) + $20^2$(0.3) = 333.2

$\sigma ^2$ = Var(x) = E[$x^2$]-$[E[x]]^2$ = 333.2 - $18.2)^2$ = 1.96

$\sigma$= 1.4

b. **If the price of a freezer having capacity of $X$ is $70X-650$, what is the expected price paid by the next customer to buy a freezer?** 

c. **What is the variance of the price paid by the next custormer?** 

d. **Suppose that although the rated capacity of a freezer is $X$, the actual capacity is $h(X)=X-0.008X^2$. What is the expected actual capacity of the freezer purchased by the next customer?** 

---

### In Class Example (7-15-2021)
Suppose that the probability of giving birth to a femal is $\frac{1}{2}$. A family decides to have children until they have a son. What is the probability of giving birth to 3 females before a son is born? 

$x$ = Number of females until a son is born

$x$~Geometric distribution with $1=\frac{1}{2}$

$P[x=3]=( \frac{1}{2})^2( \frac{1}{2})=\frac{1}{16}$

### Exercise 80 (page 135)
Let $X$ be the number of material anomalies occuring in a particulat region of an aircraft gas-turbine disk. The article **"Methodology for Probabilistic Life Prediction of Multiple-Anomaly Materials" (Amer. Inst. of Aeronautics and Astronautics J., 2006: 787-793)** proposes a Poisson distribution for X. Suppose that $\mu =4$. 

a. **Compute both $P(X\leq4)$ and $P(X<4)$.**

Using a TI-83 : [2nd] $\rightarrow$ [DISTR] $\rightarrow$  [C:poissoncdf(4,4)]

$P(X\leq4) = 0.6288$

Using a TI-83 : [2nd] $\rightarrow$ [DISTR] $\rightarrow$  [C:poissoncdf(4,3)]

$P(X<4)=P(X\leq 3) = 0.4335$

Note: $P(X=4) = 0.629-0.433 = 0.196$

b. **Compute $P(4\leq X \leq 8)$.**

$P(4\leq X \leq 8)= 0.979 - 0.4335 = 0.5455$

c. **Computer $P(8\leq X)$.**

Using a TI-83 : [2nd] $\rightarrow$ [DISTR] $\rightarrow$  [C:poissoncdf(4,8)]

$P(8\leq X) = 0.979$

d. **What is the probability that the numebr of anomalies exceeds its mean value by no more than one standard deviation?** 

$P[X>\mu + \sigma]=P[X>4+2]=P[x>6]=1-F(5)=0.21486$

### Exercise 87 (page 136)
The number of requests for assitance received by a towing service is a Poisson process with rate $\alpha =4$ per hour. 

a. **Compute the probability that exactly ten requests are received during a particular 2-hour period.** 

Using a TI-83 : [2nd] $\rightarrow$ [DISTR] $\rightarrow$  [C:poissonpdf(8,10)]

$P(X=10)=0.09926$

b. **If the operators of the towing service take a 30-min break for lunch, what is the probability that they do not miss any calls for assistance?** 

Define Y as the number of requests during a 30 minute period.

$y$~$P(\mu =\frac{4}{2}=2)$

Using a TI-83 : [2nd] $\rightarrow$ [DISTR] $\rightarrow$  [C:poissonpdf(2,0)]

$P(Y=0)=0.13533$

c. **How many calls would you expect during their break?** 

$E(Y)=2$

### Exercise 50 (page 124)
A particular telephone number is used to receive both voice calls and fax messages. Suppose that 25% of the incoming calls involve fax messages, and consider a sample of 25 incoming calls. What is the probability that

a. **At most 6 calls involve a fax message?**

[binomialcdf(25,.25,6)]=0.561

b. **Exactly 6 of the calls involve a fax message?**

$P[x=6]$ = $25\choose6$ $(0.25)^6(0.75)^{19}$

[binomialpdf(25,.25,6)]=0.1828

c. **At least 6 of the calls involve a fax message?**

[binomialpdf(25,.25,5)]=0.1828

$P(x\geq 6)=1-P[x<6]=1-P[x\leq 5]=0.6217$

d. **More than 6 of the calls involve a fax message?**

$P[x\geq 6]=1-0.5610=0.439$
