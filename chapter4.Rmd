---
title: "Chapter 4 : Continuous Random Variables and Probability Distibutions"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'chapter4.html'))})
output: 
  html_document: rmdformats::readthedown
---

# Definitions

> Let $X$ be a continuous random variable. Then a **probability distribution** or **probability density function** (pdf) of $X$ is a funciton $f(x)$ such that any two numbers a and b with $a\leq b$, $$P(\alpha \leq X \leq b) = \int_{a}^{b} f(x) dx$$ That is, the probability that $X$ takes on a value in the interval $[a,b]$ is the area above this interval and under the graph of the density funciton, as illustrated in **Figure 4.2** . The graph of $f(x)$ is often referred to as the *density curve*.  
<center>
![](img/fig4.2.png)
</center>

> A continuous random variable $X$ is said to have a **uniform distribution** on the interval $[A,B]$ if the pdf of $X$ is <center>
\[ 
f(x;A,B) = \begin{cases}
      \frac{1}{B-A} & A \leq x \leq B \\
      0 & \text{otherwise} 
   \end{cases}
\]
![](img/fig4.6and7.png)
</center>

* continuous at all possible values of interval

* cdf of x is : 
\[ 
F(X) = \begin{cases}
      0 & if x\leq A \\
      \frac{x-A}{B-A} & if A\leq x\leq B\\ 
      1 & x \geq B
   \end{cases}
\]

* cdf is always a non-decreasing function 

> The **cumulative distribution function** $F(x)$ for a continuous random variable $X$ is defined for ever number $x$ by $$F(x) = P(X \leq x ) \ \int_{- \infty}^{x} f(y)dy $$ For each $x, F(x)$ is the area under the density curve to the left of x. This is illustrated in **Figure 4.5**, where $F(x)$ increases smoothly as x increases. 
<center>
![](img/fig4.5.png)
</center>

> Let $p$ be a number between 0 and 1. The $(100p)$th **percentile** of the distribution of a continuous rv X, denoted by $\eta (p)$, is defined by $$p=F(\eta (p))=\int_{-\infty}^{\eta (p)}f(y)dy$$
<center>
![](img/fig4.10.png)
</center>

> The **median** of a continous distribution, denoterd by $\widetilde \mu$ , is the 50th percentile, so $\widetilde \mu$ satisifies $0.5=F(\widetilde \mu)$ . That is, half the area under the density curve is to the left of $\widetilde \mu$ and half is to the right of $\widetilde \mu$ . 

<center>
> ![](img/fig4.12.png)
</center>

> The **expected** or **mean value** of a continuous rv X with pdf $f(x)$ is $$\mu x=E(x)=\int_{-\infty}^{\infty}x\cdot f(x)dx$$

> The **variance** of a continuous rv X with pdf $f(x)$ and mean value $\mu$ is $$\sigma_{X}^{2}=V(X)=\int_{-\infty}^{\infty}(x-\mu)^2\cdot f(x)dx=E[(X-\mu)^2]$$

> The **standard deviation** (SD) of X is $\sigma_{X}=\sqrt{V(X)}$

> A continuous rv X is said to have a **normal distribution** with parameters $\mu$ and $\sigma$ (or $\mu$ and $\sigma ^2$), where$-\infty < \mu < \infty$ and $0<\infty$, if the pdf of X is $$f(x;\mu ,\sigma )=\frac{1}{\sqrt{2\pi }\sigma }e^{\frac{-(x-\mu)^2}{{(2\sigma ^2)}}}\quad{-\infty <x<\infty}$$ 

> The normal distribution with parameter values $\mu = 0$ and $\sigma =1$ is called the **standard normal distribution**. A rv having a standard normal distribution is called a **standard normal random variable** and will be denoted by $Z$. the pdf of $Z$ is $$f(x;0,1)=\frac{1}{\sqrt{2\pi }}e^{\frac{-z^2}{2}}\quad{-\infty <x<\infty}$$
> The graph of $f(z;0,1)$ is called the *standard normal* (or $\mathscr{z}$) curve. Its inflections points are at 1 and -1. The cdf of Z is $P(Z\leq z)=\int_{-\infty}^{z}f(y;0,1)dy$ , which we will denote by $\Phi (\mathscr{z})$ .
<center>
![](img/fig4.14.png)
</center>

* ![](img/fig4.16.png)

> A **continuity correction** is an adjustment that is made when a discrete distribution is approximated by a continuos distribution. 

* usually adding or subtracting 0.5 before standardizing 

> $X$ is said to have an **exponential distribution** with (scale) parameter $\lambda (\lambda >0)$ if the pdf of $X$ is
\[ 
f(x;\lambda ) = \begin{cases}
      \lambda e^{-\lambda x} & x\geq 0 \\
      0 &\text{otherwise}\
   \end{cases}
\]
<center>
![](img/fig4.26.png)
<\center>


* With cdf :
\[ 
F(x;\lambda ) = \begin{cases}
      0 & x< 0 \\
      1-e^{-\lambda x} &x\geq 0\
   \end{cases}
\]

> For $\alpha >0$, the **gamma function** $\Gamma (\alpha)$ is defined by $$\Gamma (\alpha)=\int_{0}^{\infty} x^{\alpha -1}e^{-x}dx$$

The most important properties of the gamma function are thus: 

* For any $\alpha >1$, $\Gamma (\alpha) = (\alpha -1)\cdot \Gamma (\alpha -1)$ [via integration by parts]

* For any positive interger $n$, $\Gamma (n)=(n-1)!$

* $\Gamma (\frac{1}{2})=\sqrt{\pi}$

pdf of a Gamma function: 
\[ 
f(x;\alpha ) = \begin{cases}
      \frac{x^{\alpha-1}e^{-x}}{\Gamma (\alpha)} & x\geq 0 \\
      0 &\text{otherwise}\
   \end{cases}
\]

> A continuous random variable $X$ is said to have a **gamma distribution** if the pdf of X is 
\[ 
f(x;\alpha ,\beta) = \begin{cases}
      \frac{x^{\alpha-1}e^{\frac{-x}{\beta}}}{\beta ^{\alpha }\Gamma (\alpha)} & x\geq 0 \\
      0 &\text{otherwise}\
   \end{cases}
\]
> where the parameters $\alpha$ and $\beta$ satisfy $\alpha > 0$, $\beta >0$. The **standard gamma distribution** has $\beta =1$, so the pdf of a standard gamma rv is given **Fig.4.27**. 
<center>
![](img/fig4.27.png)
</center>

* $E(X)=\mu =\alpha \beta$

* $V(X)=\sigma ^2=\alpha \beta ^2$

cdf of X for standard gamma rv 

* $F(x;\alpha )=\int_{0}^{x}\frac{y^{\alpha-1}e^{-y}}{\Gamma (\alpha)}dy \quad x>0$

Note that an **incomplete gamma function** doesn't have a $\Gamma (\alpha)$ in the integral

# Theorems

> **Proposition** : Let $X$ be a continuous random variable with pdf $f(x)$ and cdf $F(x)$. Then for any number $a$, $$P(X>a)=1-F(a)$$ and for any two numbers a and b with $a<b$, $$P(a \leq X \leq b) = F(b)-F(a)$$
<center>
![](img/fig4.8.png)
</center>

> **Proposition - Obtaining f(x) from F(x) :** IF X is a continuos rv with pdf $f(x)$ and cdf $F(x)$, then at every x at which the derivative $F'(x)$ exists, $F'(x)=f(x)$ .

* $f(x)=\frac{d}{dx}F(x)$ : find pdf by differentiating cdf

* $F(x)=\int_{-\infty}^{x}f(t)dt$ : find cdf by integrating pdf

* x is fixed point, do not use x within the function that being integrated (use dummy variable t)

> **Proposition :** If X is a continous rv with pdf $f(x)$ and $h(X)$ is any function of X, then $$E[h(X)]=\mu_{h}(x)=\int_{-\infty}^{\infty}h(x)\cdot f(x)dx$$

> **Proposition :** $$V(X)=E(X^2)-[E(X)]^2$$

* Special case is $U[0,1]$ where $E(X)=\frac{1}{2}$ , $Var(X)\frac{1}{12}$

> **Proposition - Nonstandard Normal Distributions :** If $X$ has a normal distribution with mean $\mu$ and standard deviation $\sigma$, then $$Z=\frac{X-\mu}{\sigma}$$ has a standard normal distribution. Thus 
\begin{equation} \label{eqa}
\begin{split}
P(a\leq X\leq b) & =P(\frac{a-\mu}{\sigma}\leq Z\leq \frac{b-\mu}{\sigma})\\
& =\Phi (\frac{b-\mu}{\sigma})-\Phi (\frac{a-\mu}{\sigma})
\end{split}
\end{equation}
$P(X\leq a) = \Phi (\frac{a-\mu}{\sigma}) \quad \quad P(X\geq b)=1-\Phi(\frac{a-\mu}{\sigma})$

<center>
* ![](img/fig4.21.png)
</center>

* If the population distribution of a variable is (approximately) normal, then : 

1. Roughly 68% oft he values are within 1 SD of the mean.
2. Roughly 95% oft he values are within 2 SD of the mean.
3. Roughly 99.7% oft he values are within 3 SD of the mean.

> **Proposition - Percentiles of an Arbitrary Normal Distribution :** $$(100p)\text{th percentile for normal} (\mu , \sigma ) = \mu +[(100p)\text{th for stadard normal}]\cdot \sigma$$

> **Proposition :** 
<center>
![](img/prop4.3.png)
</center>

> **Proposition :** 
<center>
![](img/prop4.4.png)
</center>

> **Proposition :** Suppose that the number of events occuring in any time interval of length t has a Poisson distribution with parameter $\alpha t$ (where $\alpha$ , the rate of the event process, is the expected number of events occuring in 1 unit of time) and that numbers of occurrences in nonoverlapping intervals are independednt of one another. Then the distribution of elapsed time between the occurrence of two successive events is exponential with parameter $\lambda =\alpha$

> **Proposition :** Let $X$ have a gamma distribution with parameters $\alpha$ and $\beta$. Then for any $x>0$, the dcf of $X$ is given by $$P(X\geq x)=F(x;\alpha, \beta)=F(\frac{x}{\beta};\alpha)$$ where $F(\cdot ;\alpha)$ is the incomplete gamma function.

# Examples

### Exercise 1 (page 146)
**The current in a certain circuit as measured by an ammeter is a continuous random variable X with the following density function:** 
\[ 
f(x) = \begin{cases}
      0.075x +0.2 & 3\leq x\leq 5 \\
      0 &\text{otherwise}\
   \end{cases}
\]

a. **Graph the pdf and verify that the total area under the density curve is indeed 1.** 
```{r, echo=F}
curve(0.075*x+0.2,3,5, ylim = c(0,0.75), ylab = "y")
```
\begin{equation} \label{eq1}
\begin{split}
\int_{-\infty}^{\infty}f(x)dx & =\int_{-\infty}^{3}0+\int_{3}^{5}(0.075x+0.2)dx+\int_{5}^{\infty}0\\
& =\frac{0.075x^2}{2}|_{3}^{3}+0.2(5-3)\\
& =\frac{(0.75)5^2}{2}-\frac{(0.75)3^2}{2}+0.4\\
& =1
\end{split}
\end{equation}

b. **Calculate $P(X\leq 4)$. How does this probability compare to P($X<4$)?**

\begin{equation} \label{eq2}
\begin{split}
P(X\leq 4) & =\int_{-\infty}^{4}f(x)dx\\
& =0+\int_{3}^{4}(0.70x+0.2)dx\\
& =\frac{0.075x^2}{2}+0.2|_{3}^{4}\\
& =0.4625
\end{split}
\end{equation}

$P(X\leq 4)=P(X<4)$

c. **Calculate $P(3.5\leq X\leq 4.5)$ and also P($4.5<X$).**

\begin{equation} \label{eq3}
\begin{split}
P(3.5\leq X\leq 4.5) & =\int_{3.5}^{4.5}f(x)dx\\
& =0.075\frac{x^2}{2}|_{3.5}^{4.5}+0.2\\
& =0.075(\frac{4.5^2}{2}-\frac{3.5^2}{2})+0.2\\
& =0.075(10.125-6.125)+0.2\\
& =0.5
\end{split}
\end{equation}

$P(X<4.5)=0.278125$
 
### Exercise 13 (page 155)
**Example 4.5** introducted the concept of time headway in traffic flow and proposed a particular distribution for X = the headway between two randomly selected consecutice cars (sec). Suppose that in a different traffic enviroment, the distribution of time headway has the form
\[ 
f(x) = \begin{cases}
      \frac{k}{x^4} & x>1\\
      0 & x\leq 1
   \end{cases}
\]
a. **Determine the value of $k$ for which $f(x)$ is a legitimate pdf.**
 
What is the value of k>0?
\begin{equation} \label{eq4}
\begin{split}
1 =\int_{-\infty}^{\infty}f(x)dx & =\int_{-\infty}^{1}f(x)dx+\int_{1}^{\infty}f(x)dx\\
& = 0+k\int_{1}^{\infty}\frac{1}{x^4}dx\\
& = k(\frac{x^{-3}}{-3})|_{1}^{\infty}\\
& = \frac{k}{3}
\end{split}
\end{equation}
$\Rightarrow k = 3$
 
b. **Obtain the cumulative distribuion function.** 

 $F(x)=0$ if $x\leq 1$ . So if $x>1$
 \begin{equation} \label{eq5}
\begin{split}
F(x) & =\int_{-\infty}^{x}f(t)dt \pm \int_{-\infty}^{1}f(t)dt + \int_{1}^{x}f(t)dt\\
& = 0 + \int_{1}^{x}\frac{3}{t^4}dt\\
& = 3(\frac{t^{-3}}{-3}|_{1}^{x})\\
& = 1 - \frac{1}{x^3}
\end{split}
\end{equation}
Therefore,
\[ 
F(x) = \begin{cases}
      0 & x\leq 1\\
      1 - \frac{1}{x^3} & x>1
   \end{cases}
\]
 
c. **Use the cdf from (b) to determine the probability that headway exceeds 2 sec and also the probability that headway is between 2 and 3 sec.** 
 
\begin{equation} \label{eq6}
\begin{split}
P[X>2] & =1-P[x\leq 2]\\
& = 1-F(2)\\
& = 1-(1-\frac{1}{2^3})\\
& = \frac{1}{8}
\end{split}
\end{equation}
\begin{equation} \label{eq7}
\begin{split}
P[2\leq x\leq 3] & =F(3)-F(2)\\
& = 1-\frac{1}{3^3}-(1-\frac{1}{2^3})\\
& = \frac{1}{8}-\frac{1}{27}\\
& = \frac{19}{216}
\end{split}
\end{equation}
 
d. **Obtain the mean value of headway and the standard deviation of headway** 

![](img/d.png) 
 
 e. **What is the probability that headway is within 1 standard deviation of the mean value?** 
 
 ![](img/e.png)
 
 = 0.924
 
 
 